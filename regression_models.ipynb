{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load all datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "base_path = Path('dataset/dataset_versions')\n",
    "\n",
    "datasets = {}\n",
    "datasets_names = (\n",
    "    'bfill_ffill',\n",
    "    'linear_interpolation',\n",
    "    'cubic_interpolation',\n",
    "    'quadratic_interpolation',\n",
    "    'polynomial_5_interpolation',\n",
    "    'polynomial_7_interpolation',\n",
    "    'polynomial_9_interpolation',\n",
    "    'polynomial_11_interpolation',\n",
    ")\n",
    "for dataset_name in datasets_names:\n",
    "    dataset = pd.read_excel(base_path / f'{dataset_name}_rescaled_dataset.xlsx')\n",
    "    datasets[dataset_name] = dataset.iloc[:, 1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Division into training and test samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "seed = 7\n",
    "target_feature_name = 'GDP per capita (current US$)'\n",
    "\n",
    "SplittedDataset = namedtuple('SplittedDataset', ['name', 'x_train', 'y_train', 'x_test', 'y_test'])\n",
    "splited_datasets = []\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    model = dict()\n",
    "    model['name'] = dataset_name\n",
    "    data_x = dataset.drop([target_feature_name], axis=1)\n",
    "    data_y = dataset[target_feature_name]\n",
    "    model['x_train'], model['x_test'], model['y_train'], model['y_test'] = train_test_split(data_x, data_y, test_size=test_size, random_state=seed)\n",
    "    splited_datasets.append(SplittedDataset(model['name'], model['x_train'],  model['y_train'], model['x_test'], model['y_test']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RandomForestRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "random_forest_greed_search_params = {\n",
    "    'n_estimators': [i for i in range(501, 1002, 250)],\n",
    "    'criterion' : [\"squared_error\", \"friedman_mse\"],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         dataset_name          |         r^2          |         rmse         |               best_params               \n",
      "bfill_ffill                    |  0.9927085764628596  | 0.013865629291803025 | {'criterion': 'friedman_mse', 'n_estimators': 751}\n",
      "linear_interpolation           |  0.9891716820162963  | 0.016770829744922066 | {'criterion': 'friedman_mse', 'n_estimators': 1001}\n",
      "cubic_interpolation            |  0.9907306283572973  | 0.015689853655225728 | {'criterion': 'friedman_mse', 'n_estimators': 501}\n",
      "quadratic_interpolation        |  0.992124233671234   | 0.014484178111930632 | {'criterion': 'friedman_mse', 'n_estimators': 501}\n",
      "polynomial_5_interpolation     |  0.981381955926966   | 0.022759747568716633 | {'criterion': 'squared_error', 'n_estimators': 501}\n",
      "polynomial_7_interpolation     |  0.9802373153895785  | 0.013625492485882486 | {'criterion': 'squared_error', 'n_estimators': 751}\n",
      "polynomial_9_interpolation     |  0.9511117257833476  | 0.012795656617821264 | {'criterion': 'squared_error', 'n_estimators': 1001}\n",
      "polynomial_11_interpolation    |  0.8643190719881931  | 0.022173385313356463 | {'criterion': 'squared_error', 'n_estimators': 501}\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"dataset_name\".center(30)} | {\"r^2\".center(20)} | {\"rmse\".center(20)} | {\"best_params\".center(40)}')\n",
    "for dataset in splited_datasets:\n",
    "    random_forest_model = RandomForestRegressor()\n",
    "    grid_search = GridSearchCV(random_forest_model, random_forest_greed_search_params, n_jobs=7)\n",
    "    grid_search.fit(dataset.x_train, dataset.y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    random_forest_model = RandomForestRegressor(\n",
    "        n_estimators=best_params.get('n_estimators'),\n",
    "        criterion=best_params.get('criterion')\n",
    "    )\n",
    "    random_forest_model.fit(dataset.x_train, dataset.y_train)\n",
    "    test_predict = random_forest_model.predict(dataset.x_test)\n",
    "    rmse = np.sqrt(mean_squared_error(dataset.y_test, test_predict))\n",
    "    r2 = r2_score(dataset.y_test, test_predict)\n",
    "    print(f'{str(dataset.name).ljust(30)} | {str(r2).center(20)} | {str(rmse).center(20)} | {str(best_params).center(40)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "SVR_greed_search_params = {\n",
    "    'C': [i for i in np.linspace(0.1, 100, num=20)],\n",
    "    'kernel': ['linear', 'poly'],\n",
    "    'degree': [i for i in range(2, 20)],\n",
    "    'gamma' : ['scale', 'auto']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         dataset_name          |         r^2          |         rmse         |               best_params               \n",
      "bfill_ffill                    |  0.8805023350012436  | 0.05613233798100877  | {'C': 0.1, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "linear_interpolation           |  0.8673024882754615  | 0.05870910223827949  | {'C': 5.3578947368421055, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "cubic_interpolation            |  0.8783937624782114  | 0.056829216847103896 | {'C': 5.3578947368421055, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "quadratic_interpolation        |  0.8829528955563133  | 0.05583773364949231  | {'C': 5.3578947368421055, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "polynomial_5_interpolation     |  0.8832722083266353  | 0.05698854232875017  | {'C': 5.3578947368421055, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "polynomial_7_interpolation     |  0.7112227479249504  | 0.05208476731977888  | {'C': 0.1, 'degree': 4, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "polynomial_9_interpolation     | 0.48866281097640063  | 0.04138223221369176  | {'C': 0.1, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "polynomial_11_interpolation    | 0.44774269408320255  | 0.044734577114735254 | {'C': 0.1, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"dataset_name\".center(30)} | {\"r^2\".center(20)} | {\"rmse\".center(20)} | {\"best_params\".center(40)}')\n",
    "for dataset in splited_datasets:\n",
    "    svr_model = SVR()\n",
    "    grid_search = GridSearchCV(svr_model, SVR_greed_search_params, n_jobs=7)\n",
    "    grid_search.fit(dataset.x_train, dataset.y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    best_svr_model = SVR(\n",
    "        C=best_params.get('C'),\n",
    "        kernel=best_params.get('kernel')\n",
    "    )\n",
    "    best_svr_model.fit(dataset.x_train, dataset.y_train)\n",
    "\n",
    "    test_predict = best_svr_model.predict(dataset.x_test)\n",
    "    rmse = np.sqrt(mean_squared_error(dataset.y_test, test_predict))\n",
    "    r2 = r2_score(dataset.y_test, test_predict)\n",
    "    print(f'{str(dataset.name).ljust(30)} | {str(r2).center(20)} | {str(rmse).center(20)} | {str(best_params).center(40)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         dataset_name          |         r^2          |         rmse         |               best_params               \n",
      "bfill_ffill                    |  0.9907301382096394  | 0.015633997977031588 |                    -                    \n",
      "linear_interpolation           |  0.9936182915645295  | 0.012874860405056891 |                    -                    \n",
      "cubic_interpolation            |  0.9933571470215885  | 0.013282232117914659 |                    -                    \n",
      "quadratic_interpolation        |  0.9928675371474754  | 0.013783744197748153 |                    -                    \n",
      "polynomial_5_interpolation     |  0.9904417993650888  | 0.01630754122810385  |                    -                    \n",
      "polynomial_7_interpolation     |  0.975561579469896   | 0.015151854997984233 |                    -                    \n",
      "polynomial_9_interpolation     |  0.989144554267107   | 0.006029538240341453 |                    -                    \n",
      "polynomial_11_interpolation    |  0.9974777033332043  | 0.0030232264896568957 |                    -                    \n"
     ]
    }
   ],
   "source": [
    "print(f'{\"dataset_name\".center(30)} | {\"r^2\".center(20)} | {\"rmse\".center(20)} | {\"best_params\".center(40)}')\n",
    "for dataset in splited_datasets:\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(dataset.x_train, dataset.y_train)\n",
    "    test_predict = linear_model.predict(dataset.x_test)\n",
    "    rmse = np.sqrt(mean_squared_error(dataset.y_test, test_predict))\n",
    "    r2 = r2_score(dataset.y_test, test_predict)\n",
    "    print(f'{str(dataset.name).ljust(30)} | {str(r2).center(20)} | {str(rmse).center(20)} | {\"-\".center(40)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DecisionTreeRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "tree_greed_search_params = {\n",
    "    'splitter': [\"best\", \"random\"],\n",
    "    'criterion' : [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         dataset_name          |         r^2          |         rmse         |               best_params               \n",
      "bfill_ffill                    |  0.9757073522556675  | 0.02530875888086164  | {'criterion': 'poisson', 'splitter': 'best'}\n",
      "linear_interpolation           |  0.9351957363164844  | 0.041027574231159734 | {'criterion': 'absolute_error', 'splitter': 'best'}\n",
      "cubic_interpolation            |  0.9783995534258159  | 0.023951080493251734 | {'criterion': 'absolute_error', 'splitter': 'best'}\n",
      "quadratic_interpolation        |  0.9748538354846877  | 0.02588113522106923  | {'criterion': 'absolute_error', 'splitter': 'best'}\n",
      "polynomial_5_interpolation     |  0.8330751012617197  | 0.06814923336085207  | {'criterion': 'poisson', 'splitter': 'random'}\n",
      "polynomial_7_interpolation     |  0.9249456231984227  | 0.026553223456380774 | {'criterion': 'friedman_mse', 'splitter': 'best'}\n",
      "polynomial_9_interpolation     |  0.7301518064058589  | 0.030062146102732296 | {'criterion': 'squared_error', 'splitter': 'random'}\n",
      "polynomial_11_interpolation    | -2.9557552163146457  | 0.11972567823817831  | {'criterion': 'absolute_error', 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"dataset_name\".center(30)} | {\"r^2\".center(20)} | {\"rmse\".center(20)} | {\"best_params\".center(40)}')\n",
    "for dataset in splited_datasets:\n",
    "    tree_model = DecisionTreeRegressor()\n",
    "    grid_search = GridSearchCV(tree_model, tree_greed_search_params, n_jobs=7)\n",
    "    grid_search.fit(dataset.x_train, dataset.y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    best_tree_model = DecisionTreeRegressor(\n",
    "        splitter=best_params.get('splitter'),\n",
    "        criterion=best_params.get('criterion')\n",
    "    )\n",
    "    best_tree_model.fit(dataset.x_train, dataset.y_train)\n",
    "    test_predict = best_tree_model.predict(dataset.x_test)\n",
    "    rmse = np.sqrt(mean_squared_error(dataset.y_test, test_predict))\n",
    "    r2 = r2_score(dataset.y_test, test_predict)\n",
    "    print(f'{str(dataset.name).ljust(30)} | {str(r2).center(20)} | {str(rmse).center(20)} | {str(best_params).center(40)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "best_models_per_dataset = {\n",
    "    splited_datasets[0].name:  [\n",
    "        {'model': SVR(C=0.1, degree=2, gamma='scale', kernel='linear'), 'name': 'svr_model'},\n",
    "        {'model': LinearRegression(), 'name': 'linear_model'},\n",
    "        {'model': DecisionTreeRegressor(criterion='poisson', splitter='best'), 'name': 'decision_tree'}\n",
    "    ],\n",
    "\n",
    "    splited_datasets[1].name:  [\n",
    "        {'model': SVR(C=5.3578947368421055, degree=2, gamma='scale', kernel='poly'), 'name': 'svr_model'},\n",
    "        {'model': LinearRegression(), 'name': 'linear_model'},\n",
    "        {'model': DecisionTreeRegressor(criterion='absolute_error', splitter='best'), 'name': 'decision_tree'}\n",
    "    ],\n",
    "\n",
    "    splited_datasets[2].name:  [\n",
    "        {'model': SVR(C=5.3578947368421055, degree=3, gamma='scale', kernel='poly'), 'name': 'svr_model'},\n",
    "        {'model': LinearRegression(), 'name': 'linear_model'},\n",
    "        {'model': DecisionTreeRegressor(criterion='absolute_error', splitter='best'), 'name': 'decision_tree'}\n",
    "    ],\n",
    "\n",
    "    splited_datasets[3].name:  [\n",
    "        {'model': SVR(C=5.3578947368421055, degree=3, gamma='scale', kernel='poly'), 'name': 'svr_model'},\n",
    "        {'model': LinearRegression(), 'name': 'linear_model'},\n",
    "        {'model': DecisionTreeRegressor(criterion='absolute_error', splitter='best'), 'name': 'decision_tree'}\n",
    "    ],\n",
    "\n",
    "    splited_datasets[4].name:  [\n",
    "        {'model': SVR(C=5.3578947368421055, degree=3, gamma='scale', kernel='poly'), 'name': 'svr_model'},\n",
    "        {'model': LinearRegression(), 'name': 'linear_model'},\n",
    "        {'model': DecisionTreeRegressor(criterion='poisson', splitter='random'), 'name': 'decision_tree'}\n",
    "    ],\n",
    "\n",
    "    splited_datasets[5].name:  [\n",
    "        {'model': SVR(C=0.1, degree=4, gamma='scale', kernel='poly'), 'name': 'svr_model'},\n",
    "        {'model': LinearRegression(), 'name': 'linear_model'},\n",
    "        {'model': DecisionTreeRegressor(criterion=\"friedman_mse\", splitter='best'), 'name': 'decision_tree'}\n",
    "    ],\n",
    "\n",
    "    splited_datasets[6].name:  [\n",
    "        {'model': SVR(C=0.1, degree=2, gamma='scale', kernel='linear'), 'name': 'svr_model'},\n",
    "        {'model': LinearRegression(), 'name': 'linear_model'},\n",
    "        {'model': DecisionTreeRegressor(criterion='squared_error', splitter='random'), 'name': 'decision_tree'}\n",
    "    ],\n",
    "\n",
    "    splited_datasets[7].name:  [\n",
    "        {'model': SVR(C=0.1, degree=2, gamma='scale', kernel='linear'), 'name': 'svr_model'},\n",
    "        {'model': LinearRegression(), 'name': 'linear_model'},\n",
    "        {'model': DecisionTreeRegressor(criterion='absolute_error', splitter='best'), 'name': 'decision_tree'}\n",
    "    ]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bagging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         dataset_name          |   The model on which bagging is based    |         r^2          |         rmse        \n",
      "bfill_ffill                    |                svr_model                 |  0.8677539562228549  | 0.05905066139206543 \n",
      "bfill_ffill                    |               linear_model               |  0.9882000947793678  | 0.01763894805953474 \n",
      "bfill_ffill                    |              decision_tree               |  0.9933199941783071  | 0.013271555952638627\n",
      "linear_interpolation           |                svr_model                 |  0.8607492392914218  | 0.060141303654964284\n",
      "linear_interpolation           |               linear_model               |  0.993941476482994   | 0.012544618221731339\n",
      "linear_interpolation           |              decision_tree               |  0.986705890559078   | 0.01858248002077375 \n",
      "cubic_interpolation            |                svr_model                 |  0.8644326861524738  | 0.06000276184064881 \n",
      "cubic_interpolation            |               linear_model               |  0.9933817210574245  | 0.01325764174451518 \n",
      "cubic_interpolation            |              decision_tree               |  0.9892352276660296  |  0.0169081530350948 \n",
      "quadratic_interpolation        |                svr_model                 |  0.8658110556861216  | 0.05978686946520868 \n",
      "quadratic_interpolation        |               linear_model               |  0.9935127000134765  | 0.013145570422889882\n",
      "quadratic_interpolation        |              decision_tree               |  0.9901064352947991  | 0.01623393657156713 \n",
      "polynomial_5_interpolation     |                svr_model                 |  0.863757114387181   | 0.06156832387536539 \n",
      "polynomial_5_interpolation     |               linear_model               |  0.9923876335833861  | 0.014553258926251185\n",
      "polynomial_5_interpolation     |              decision_tree               |  0.9881484458334034  | 0.01815883852715905 \n",
      "polynomial_7_interpolation     |                svr_model                 |  0.6541216210257894  | 0.05700211186336128 \n",
      "polynomial_7_interpolation     |               linear_model               |  0.9790919579256293  | 0.014014768273194624\n",
      "polynomial_7_interpolation     |              decision_tree               |  0.9816404488740939  | 0.013132888833318678\n",
      "polynomial_9_interpolation     |                svr_model                 | 0.34617571171066075  | 0.046794062246033434\n",
      "polynomial_9_interpolation     |               linear_model               |  0.9937488811005141  | 0.004575505727289116\n",
      "polynomial_9_interpolation     |              decision_tree               |  0.9704601915714963  | 0.009946357405501568\n",
      "polynomial_11_interpolation    |                svr_model                 |  0.2729340582408265  | 0.05132860980488954 \n",
      "polynomial_11_interpolation    |               linear_model               |  0.9979936395421362  | 0.002696355066702219\n",
      "polynomial_11_interpolation    |              decision_tree               |  0.9103811609668812  | 0.018020724947291792\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"dataset_name\".center(30)} | {\"The model on which bagging is based\".center(40)} | {\"r^2\".center(20)} | {\"rmse\".center(20)}')\n",
    "for dataset in splited_datasets:\n",
    "    models = best_models_per_dataset[dataset.name]\n",
    "    for model in models:\n",
    "        bagging_model = BaggingRegressor(model.get('model'), max_samples=200, n_estimators=300)\n",
    "        bagging_model.fit(dataset.x_train, dataset.y_train)\n",
    "        test_predict = bagging_model.predict(dataset.x_test)\n",
    "        rmse = np.sqrt(mean_squared_error(dataset.y_test, test_predict))\n",
    "        r2 = r2_score(dataset.y_test, test_predict)\n",
    "        print(f'{str(dataset.name).ljust(30)} | {model.get(\"name\").center(40)} | {str(r2).center(20)} | {str(rmse).center(20)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GradientBoostingRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "gradient_boosting_search_params = {\n",
    "    'loss': ['squared_error', 'absolute_error', 'huber'],\n",
    "    'learning_rate' : [i for i in np.linspace(0.1, 2, num=5)],\n",
    "    'n_estimators' : [100, 200, 300],\n",
    "    'criterion': ['friedman_mse', 'squared_error']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         dataset_name          |         r^2          |         rmse         |               best_params               \n",
      "bfill_ffill                    |  0.9950358018360845  | 0.01144084170342771  | {'criterion': 'squared_error', 'learning_rate': 0.1, 'loss': 'squared_error', 'n_estimators': 200}\n",
      "linear_interpolation           |  0.9808573445216046  | 0.022298473908945026 | {'criterion': 'squared_error', 'learning_rate': 0.1, 'loss': 'squared_error', 'n_estimators': 300}\n",
      "cubic_interpolation            |  0.9913013595601345  | 0.015199154690839578 | {'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'squared_error', 'n_estimators': 200}\n",
      "quadratic_interpolation        |  0.9908228756602306  | 0.015635103249040744 | {'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'squared_error', 'n_estimators': 100}\n",
      "polynomial_5_interpolation     |  0.9911741542294307  | 0.01567034582488927  | {'criterion': 'squared_error', 'learning_rate': 0.1, 'loss': 'squared_error', 'n_estimators': 300}\n",
      "polynomial_7_interpolation     |  0.9834777820291698  | 0.012458432751764848 | {'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'squared_error', 'n_estimators': 300}\n",
      "polynomial_9_interpolation     |  0.9177065935509627  | 0.016601324685203443 | {'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'huber', 'n_estimators': 300}\n",
      "polynomial_11_interpolation    |  0.8268495906234433  | 0.025048652198053096 | {'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'huber', 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"dataset_name\".center(30)} | {\"r^2\".center(20)} | {\"rmse\".center(20)} | {\"best_params\".center(40)}')\n",
    "for dataset in splited_datasets:\n",
    "    model = GradientBoostingRegressor()\n",
    "    grid_search = GridSearchCV(model, gradient_boosting_search_params, n_jobs=7)\n",
    "    grid_search.fit(dataset.x_train, dataset.y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = GradientBoostingRegressor(\n",
    "        loss=best_params.get('loss'),\n",
    "        learning_rate=best_params.get('learning_rate'),\n",
    "        n_estimators=best_params.get('n_estimators'),\n",
    "        criterion=best_params.get('criterion')\n",
    "    )\n",
    "    best_model.fit(dataset.x_train, dataset.y_train)\n",
    "    test_predict = best_model.predict(dataset.x_test)\n",
    "    rmse = np.sqrt(mean_squared_error(dataset.y_test, test_predict))\n",
    "    r2 = r2_score(dataset.y_test, test_predict)\n",
    "    print(f'{str(dataset.name).ljust(30)} | {str(r2).center(20)} | {str(rmse).center(20)} | {str(best_params).center(40)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "AdaBoostRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "gradient_boosting_search_params = {\n",
    "    'loss': ['linear', 'square', 'exponential'],\n",
    "    'learning_rate' : [i for i in np.linspace(0.1, 2, num=5)],\n",
    "    'n_estimators' : [100, 200, 300],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         dataset_name          |         r^2          |         rmse         |               best_params               \n",
      "bfill_ffill                    |  0.9883532696967754  |  0.017524088239988   | {'estimator': LinearRegression(), 'learning_rate': 2.0, 'loss': 'exponential', 'n_estimators': 100}\n",
      "linear_interpolation           |  0.9943279088224458  | 0.012137958586833782 | {'estimator': LinearRegression(), 'learning_rate': 0.1, 'loss': 'linear', 'n_estimators': 100}\n",
      "cubic_interpolation            |  0.9947564525259688  | 0.011800661353918081 | {'estimator': LinearRegression(), 'learning_rate': 0.1, 'loss': 'linear', 'n_estimators': 200}\n",
      "quadratic_interpolation        |  0.9936775334792448  | 0.012977490352826216 | {'estimator': LinearRegression(), 'learning_rate': 0.1, 'loss': 'linear', 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniil_Alenushkin\\Desktop\\SUAI\\Magistracy_09.04.04\\predicting_a_country_economic_potential\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "6 fits failed out of a total of 675.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Daniil_Alenushkin\\Desktop\\SUAI\\Magistracy_09.04.04\\predicting_a_country_economic_potential\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Daniil_Alenushkin\\Desktop\\SUAI\\Magistracy_09.04.04\\predicting_a_country_economic_potential\\env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Daniil_Alenushkin\\Desktop\\SUAI\\Magistracy_09.04.04\\predicting_a_country_economic_potential\\env\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 171, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "  File \"C:\\Users\\Daniil_Alenushkin\\Desktop\\SUAI\\Magistracy_09.04.04\\predicting_a_country_economic_potential\\env\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1168, in _boost\n",
      "    estimator.fit(X_, y_)\n",
      "  File \"C:\\Users\\Daniil_Alenushkin\\Desktop\\SUAI\\Magistracy_09.04.04\\predicting_a_country_economic_potential\\env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Daniil_Alenushkin\\Desktop\\SUAI\\Magistracy_09.04.04\\predicting_a_country_economic_potential\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1320, in fit\n",
      "    super()._fit(\n",
      "  File \"C:\\Users\\Daniil_Alenushkin\\Desktop\\SUAI\\Magistracy_09.04.04\\predicting_a_country_economic_potential\\env\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 264, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Sum of y is not positive which is necessary for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Daniil_Alenushkin\\Desktop\\SUAI\\Magistracy_09.04.04\\predicting_a_country_economic_potential\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.90781464 0.91098319 0.90211682 0.91236246 0.9140677  0.91376811\n",
      " 0.91489101 0.91443082 0.91440392 0.88372132 0.90573889 0.90628617\n",
      " 0.91462183 0.91052916 0.90729118 0.91345311 0.91419408 0.9158961\n",
      " 0.90092891 0.9087183  0.89998996 0.90951005 0.90342242 0.88662235\n",
      " 0.91330684 0.91390952 0.91317997 0.90651379 0.90477705 0.87896747\n",
      " 0.90967082 0.90290433 0.9118363  0.91230396 0.91362285 0.91191117\n",
      " 0.89184    0.88537838 0.87740874 0.90361354 0.89617001 0.90397923\n",
      " 0.90776635 0.91547522 0.91644936 0.99125901 0.99123636 0.99127304\n",
      " 0.99122946 0.99130994 0.99130109 0.99105323 0.99112654 0.99129752\n",
      " 0.99127115 0.99141548 0.99130423 0.99075824 0.99080005 0.99058011\n",
      " 0.99128084 0.99135226 0.99133205 0.99124661 0.99121557 0.99128143\n",
      " 0.98873368 0.98735544 0.98655001 0.99130963 0.99141375 0.99125957\n",
      " 0.99030952 0.99054099 0.9901165  0.84579766 0.81568443 0.87324657\n",
      " 0.99119038 0.99133381 0.99127326 0.95745388 0.95309739 0.95129303\n",
      " 0.54832518 0.61664099 0.37642387 0.99128672 0.99101136 0.99117833\n",
      " 0.97569129 0.97824826 0.97858324 0.97508709 0.97919733 0.97791277\n",
      " 0.9756325  0.97732171 0.97784838 0.97619542 0.97918592 0.9770543\n",
      " 0.97426277 0.97294055 0.97671993 0.97627348 0.97864806 0.97795058\n",
      " 0.97605555 0.97634855 0.97893047 0.97194683 0.97254188 0.96950942\n",
      " 0.97549317 0.97760985 0.9779282  0.96930907 0.96994777 0.97053322\n",
      " 0.91965204 0.90001162 0.90142221 0.98006343 0.97938197 0.97727103\n",
      " 0.93632988 0.93372519 0.93707649        nan        nan        nan\n",
      " 0.97564494 0.97666021 0.97636547]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polynomial_5_interpolation     |  0.9932893442167926  | 0.013664158631770376 | {'estimator': LinearRegression(), 'learning_rate': 0.575, 'loss': 'linear', 'n_estimators': 200}\n",
      "polynomial_7_interpolation     |  0.9796548170957783  |  0.0138248375854265  | {'estimator': LinearRegression(), 'learning_rate': 1.525, 'loss': 'exponential', 'n_estimators': 300}\n",
      "polynomial_9_interpolation     |  0.9956791498520575  | 0.0038040378187853326 | {'estimator': LinearRegression(), 'learning_rate': 2.0, 'loss': 'exponential', 'n_estimators': 200}\n",
      "polynomial_11_interpolation    |  0.998481328691613   | 0.002345872992157921 | {'estimator': LinearRegression(), 'learning_rate': 2.0, 'loss': 'exponential', 'n_estimators': 100}\n",
      "         dataset_name          |         r^2          |         rmse         |               best_params               \n",
      "bfill_ffill                    |  0.990022173252303   | 0.016220020592671112 | {'estimator': LinearRegression(), 'learning_rate': 0.1, 'loss': 'square', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"dataset_name\".center(30)} | {\"r^2\".center(20)} | {\"rmse\".center(20)} | {\"best_params\".center(40)}')\n",
    "for dataset in splited_datasets:\n",
    "    ensemble_models = best_models_per_dataset[dataset.name]\n",
    "    gradient_boosting_search_params['estimator'] = [ensemble_model['model'] for ensemble_model in ensemble_models]\n",
    "\n",
    "    model = AdaBoostRegressor()\n",
    "    grid_search = GridSearchCV(model, gradient_boosting_search_params, n_jobs=7)\n",
    "    grid_search.fit(dataset.x_train, dataset.y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = AdaBoostRegressor(\n",
    "        loss=best_params.get('loss'),\n",
    "        learning_rate=best_params.get('learning_rate'),\n",
    "        n_estimators=best_params.get('n_estimators'),\n",
    "        estimator=best_params.get('estimator')\n",
    "    )\n",
    "    best_model.fit(dataset.x_train, dataset.y_train)\n",
    "    test_predict = best_model.predict(dataset.x_test)\n",
    "    rmse = np.sqrt(mean_squared_error(dataset.y_test, test_predict))\n",
    "    r2 = r2_score(dataset.y_test, test_predict)\n",
    "    print(f'{str(dataset.name).ljust(30)} | {str(r2).center(20)} | {str(rmse).center(20)} | {str(best_params).center(40)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
